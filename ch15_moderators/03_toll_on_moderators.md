# The Toll on Moderators

When social media companies like Facebook hire moderators, they often hire teams in countries where they can pay workers less. The moderators then are given sets of content to moderate and have to make quick decisions about each item before looking at the next one. They have to get through many posts during their time, and given the nature of the content (e.g., hateful content, CSAM, videos of murder, etc.), this can be traumatizing for the moderators:
- [Facebook Is Ignoring Moderators’ Trauma: ‘They Suggest Karaoke and Painting’](https://www.vice.com/en/article/m7eva4/traumatized-facebook-moderators-told-to-suck-it-up-and-try-karaoke) {cite:p}`gilbertFacebookIgnoringModerators2021`


In addition to the trauma, by finding places where they can pay workers less and get them to do undesirable work, they are exploiting current inequalities to increase their profits. So, for example, "[Colombia’s Ministry of Labor has launched an investigation into TikTok subcontractor Teleperformance [for content moderators], relating to alleged union-busting, traumatic working conditions and low pay]"(https://time.com/6231625/tiktok-teleperformance-colombia-investigation/) {cite:p}`TikTokSubcontractorColombia2022`

## Reflection Questions
- What support should content moderators have from social media companies and from governments?
- Do you think there are ways to moderate well that involve less traumatizing of moderators or taking advantage of poor people?

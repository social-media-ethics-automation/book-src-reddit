
# Citations for ch21_conclusions/02_ethics_tech.md
@misc{PhaedrusPlato,
	title = {Phaedrus: {Translated} by {Benjamin} {Jowett}},
	isbn = {978-1-5432-6676-4},
	shorttitle = {Phaedrus},
	abstract = {INTRODUCTION. The Phaedrus is closely connected with the Symposium, and may be regarded either as introducing or following it. The two Dialogues together contain the whole philosophy of Plato on the nature of love, which in the Republic and in the later writings of Plato is only introduced playfully or as a figure of speech. But in the Phaedrus and Symposium love and philosophy join hands, and one is an aspect of the other. The spiritual and emotional part is elevated into the ideal, to which in the Symposium mankind are described as looking forward, and which in the Phaedrus, as well as in the Phaedo, they are seeking to recover from a former state of existence. Whether the subject of the Dialogue is love or rhetoric, or the union of the two, or the relation of philosophy to love and to art in general, and to the human soul, will be hereafter considered. And perhaps we may arrive at some conclusion such as the following-that the dialogue is not strictly confined to a single subject, but passes from one to another with the natural freedom of conversation. Phaedrus has been spending the morning with Lysias, the celebrated rhetorician, and is going to refresh himself by taking a walk outside the wall, when he is met by Socrates, who professes that he will not leave him until he has delivered up the speech with which Lysias has regaled him, and which he is carrying about in his mind, or more probably in a book hidden under his cloak, and is intending to study as he walks. The imputation is not denied, and the two agree to direct their steps out of the public way along the stream of the Ilissus towards a plane-tree which is seen in the distance.},
	language = {en},
	urldate = {2023-12-10},
	publisher = {Project Gutenberg},
	author = {Plato},
	month = jan,
	year = {2013},
	note = {Page Version ID: 1189255462},
}

@misc{Luddite2023,
	title = {Luddite},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Luddite&oldid=1189255462},
	abstract = {The Luddites were members of a 19th-century movement of English textile workers which opposed the use of certain types of cost-saving machinery, often by destroying the machines in clandestine raids. They protested against manufacturers who used machines in "a fraudulent and deceitful manner" to replace the skilled labour of workers and drive down wages by producing inferior goods. Members of the group referred to themselves as Luddites, self-described followers of "Ned Ludd", a legendary weaver whose name was used as a pseudonym in threatening letters to mill owners and government officials.The Luddite movement began in Nottingham, England, and spread to the North West and Yorkshire between 1811 and 1816. Mill and factory owners took to shooting protesters and eventually the movement was suppressed with legal and military force, which included execution and penal transportation of accused and convicted Luddites.Over time, the term has been used to refer to those opposed to industrialisation, automation, computerisation, or new technologies in general.},
	language = {en},
	urldate = {2023-12-10},
	journal = {Wikipedia},
	month = dec,
	year = {2023},
	note = {Page Version ID: 1189255462},
}

@article{chiangWillBecomeNew2023,
	title = {Will {A}.{I}. {Become} the {New} {McKinsey}?},
	issn = {0028-792X},
	url = {https://www.newyorker.com/science/annals-of-artificial-intelligence/will-ai-become-the-new-mckinsey},
	abstract = {As it‚Äôs currently imagined, the technology promises to concentrate wealth and disempower workers. Is an alternative possible?},
	language = {en-US},
	urldate = {2023-12-10},
	journal = {The New Yorker},
	author = {Chiang, Ted},
	month = may,
	year = {2023},
	keywords = {artificial intelligence, capitalism, economics, labor, machine learning, technology},
}

@misc{PaceModernLife,
	title = {The {Pace} of {Modern} {Life}},
	url = {https://xkcd.com/1227/},
	urldate = {2023-12-10},
	journal = {xkcd},
	author = {xkcd comics},
	month = jun,
	year = {2013},
}

@misc{1227PaceModern,
	title = {1227: {The} {Pace} of {Modern} {Life} - explain xkcd},
	url = {https://www.explainxkcd.com/wiki/index.php/1227:_The_Pace_of_Modern_Life},
	language = {en},
	urldate = {2023-12-10},
	journal = {explain xkcd},
	author = {xkcd comics},
	month = jun,
	year = {2013},
}

@misc{spielbergJurassicPark1993,
	type = {Action, {Adventure}, {Sci}-{Fi}},
	title = {Jurassic {Park}},
	url = {https://www.imdb.com/title/tt0107290/},
	abstract = {A pragmatic paleontologist touring an almost complete theme park on an island in Central America is tasked with protecting a couple of kids after a power failure causes the park\&apos;s cloned dinosaurs to run loose.},
	publisher = {Universal Pictures, Amblin Entertainment},
	author = {Spielberg, Steven},
	collaborator = {Crichton, Michael and Koepp, David and Neill, Sam and Dern, Laura and Goldblum, Jeff},
	month = jun,
	year = {1993},
	keywords = {bipedal dinosaur, dinosaur, scientist, sneeze, tyrannosaurus rex},
}

@misc{alexblechman[@alexblechman]SciFiAuthorMy2021a,
	type = {Tweet},
	title = {Sci-{Fi} {Author}: {In} my book {I} invented the {Torment} {Nexus} as a cautionary tale {Tech} {Company}: {At} long last, we have created the {Torment} {Nexus} from classic sci-fi novel {Don}'t {Create} {The} {Torment} {Nexus}},
	url = {https://twitter.com/AlexBlechman/status/1457842724128833538},
	language = {en},
	urldate = {2023-12-10},
	journal = {Twitter},
	author = {{Alex Blechman [@AlexBlechman]}},
	month = nov,
	year = {2021},
}

@misc{altschulerSiliconValley2014a,
	type = {Comedy},
	title = {Silicon {Valley}},
	url = {https://www.imdb.com/title/tt2575988/},
	abstract = {Follows the struggle of Richard Hendricks, a Silicon Valley engineer trying to build his own company called Pied Piper.},
	publisher = {3 Arts Entertainment, Altschuler Krinsky Works, Judgemental Films Inc.},
	collaborator = {Altschuler, John and Judge, Mike and Krinsky, Dave and Middleditch, Thomas and Miller, T. J. and Brener, Josh},
	month = apr,
	year = {2014},
	keywords = {business rivalry, computer, computer nerd, satanist, startup},
}

@misc{EliWhitney2023,
	title = {Eli {Whitney}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Eli_Whitney&oldid=1189351897},
	abstract = {Eli Whitney Jr. (December 8, 1765 ‚Äì January 8, 1825) was an American inventor, widely known for inventing the cotton gin in 1793, one of the key inventions of the Industrial Revolution that shaped the economy of the Antebellum South.Whitney's invention made upland short cotton into a profitable crop, which strengthened the economic foundation of slavery in the United States and prolonged the institution. Despite the social and economic impact of his invention, Whitney lost much of his profits in legal battles over patent infringement for the cotton gin. Thereafter, he turned his attention to securing contracts with the government in the manufacture of muskets for the newly formed United States Army. He continued making arms and inventing until his death in 1825.},
	language = {en},
	urldate = {2023-12-10},
	journal = {Wikipedia},
	month = dec,
	year = {2023},
	note = {Page Version ID: 1189351897},
}

@misc{AlfredNobel2023,
	title = {Alfred {Nobel}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Alfred_Nobel&oldid=1189282550},
	abstract = {Alfred Bernhard Nobel (21 October 1833 ‚Äì 10 December 1896) was a Swedish chemist, engineer, inventor, businessman, and philanthropist. He is known for inventing dynamite as well as having bequeathed his fortune to establish the Nobel Prize. He also made several important contributions to science, holding 355 patents in his lifetime. Nobel's most famous invention was dynamite, an explosive using  nitroglycerin; it was patented in 1867.
	Nobel displayed an early aptitude for science and learning, particularly in chemistry and languages; he became fluent in six languages and filed his first patent at the age of 24. He embarked on many business ventures with his family, most notably owning the company Bofors, which was an iron and steel producer that he had developed into a major manufacturer of cannons and other armaments.
	Nobel was later inspired to donate his fortune to the Nobel Prize institution, which would annually recognize those who "conferred the greatest benefit to humankind". The synthetic element nobelium was named after him, and his name and legacy also survives in companies such as Dynamit Nobel and AkzoNobel, which descend from mergers with companies he founded.
	Nobel was elected a member of the Royal Swedish Academy of Sciences, which, pursuant to his will, would be responsible for choosing the Nobel laureates in physics and in chemistry.},
	language = {en},
	urldate = {2023-12-10},
	journal = {Wikipedia},
	month = dec,
	year = {2023},
	note = {Page Version ID: 1189282550},
}

@misc{EinsteinManhattanProject,
	title = {Einstein and the {Manhattan} {Project}},
	url = {https://www.amnh.org/exhibitions/einstein/peace-and-war/the-manhattan-project},
	abstract = {Einstein expressed regret for urging President Roosevelt to research atomic weapons.},
	language = {en-US},
	urldate = {2023-12-10},
	journal = {American Museum of Natural History},
}


# Citations for ch21_conclusions/03_going_forward/03_potential_tech_worker.md
@misc{stevekrenzel[@stevekrenzel]TwitterChangeOwnership2022,
	type = {Tweet},
	title = {With {Twitter}'s change in ownership last week, {I}'m probably in the clear to talk about the most unethical thing {I} was asked to build while working at {Twitter}. üßµ},
	url = {https://twitter.com/stevekrenzel/status/1589700721121058817},
	language = {en},
	urldate = {2023-12-10},
	journal = {Twitter},
	author = {{Steve Krenzel [@stevekrenzel]}},
	month = nov,
	year = {2022},
}

@misc{nguyenExTwitterEngineerSays,
	title = {Ex-{Twitter} engineer says he quit years ago after refusing to help sell identifiable user data, worries {Elon} {Musk} will 'do far worse things with data'},
	url = {https://www.businessinsider.com/former-twitter-engineer-worried-how-elon-musk-treat-user-data-2022-11},
	abstract = {Steve Krenzel said he left his job as a Twitter software engineer after being asked to help sell identifiable user location data to a telecom company.},
	language = {en-US},
	urldate = {2023-12-10},
	journal = {Business Insider},
	author = {Nguyen, Britney},
	month = nov,
	year = {2022},
}

@misc{OurPeople,
	title = {Our {People:} {Workers are coming together to build power across {Alphabet}}},
	shorttitle = {Our {People}},
	url = {https://www.alphabetworkersunion.org/our-people},
	abstract = {We recognize our power as Alphabet workers‚Äîfull-time employees, temporary employees, vendors, raters, and contractors‚Äîcomes from our solidarity with one another. Learn about some of our members.},
	language = {en},
	urldate = {2023-12-10},
	author = {Alphabet Workers Union-Communications Workers of America Local 9009},
	organization = {AWU-CWA Local 9009},
}


# Citations for ch21_conclusions/05_more_resources.md
@article{parhamPeopleHistoryBlack2,
	title = {A {People}‚Äôs {History} of {Black} {Twitter}, {Part} {I}},
	issn = {1059-1028},
	url = {https://www.wired.com/story/black-twitter-oral-history-part-i-coming-together/},
	abstract = {From \#UKnowUrBlackWhen to \#BlackLivesMatter, how a loose online network became a pop culture juggernaut, an engine of social justice, and a lens into the future.},
	language = {en-US},
	urldate = {2023-12-10},
	journal = {Wired},
	author = {Parham, Jason},
	month = jul,
	year = {2021},
	keywords = {black twitter, black twitter series, cover story, history, longreads, magazine-29.09, twitter},
}

@article{parhamThereNoReplacement,
	title = {There {Is} {No} {Replacement} for {Black} {Twitter}},
	issn = {1059-1028},
	url = {https://www.wired.com/story/black-twitter-elon-musk/},
	abstract = {A series of missteps by Elon Musk has called the fate of the platform‚Äôs cultural engine into question.},
	language = {en-US},
	urldate = {2023-12-10},
	journal = {Wired},
	author = {Parham, Jason},
	month = nov,
	year = {2022},
	keywords = {black twitter, elon musk, twitter},
}

@misc{buniMediaCompanyBehemoth2016,
	title = {Media, company, behemoth: {What}, exactly, is {Facebook}?},
	shorttitle = {Media, company, behemoth},
	url = {https://www.theverge.com/2016/11/16/13655102/facebook-journalism-ethics-media-company-algorithm-tax},
	abstract = {What, exactly, is Facebook?},
	language = {en},
	urldate = {2023-12-10},
	journal = {The Verge},
	author = {Buni, Catherine},
	month = nov,
	year = {2016},
}

@misc{letzterTeenagerTikTokDisrupted2021a,
	title = {A teenager on {TikTok} disrupted thousands of scientific studies with a single video},
	url = {https://www.theverge.com/2021/9/24/22688278/tiktok-science-study-survey-prolific},
	abstract = {One TikTok created a mystery for some scientific surveys.},
	language = {en},
	urldate = {2023-12-10},
	journal = {The Verge},
	author = {Letzter, Rafi},
	month = sep,
	year = {2021},
}

@book{dignazioDataFeminism2020a,
	address = {Cambridge},
	edition = {1},
	series = {Strong {Ideas}},
	title = {Data {Feminism}},
	isbn = {978-0-262-04400-4},
	url = {https://direct.mit.edu/books/oa-monograph/4660/Data-Feminism},
	abstract = {A new way of thinking about data science and data ethics that is informed by the ideas of intersectional feminism.
	The open access edition of this book was made possible by generous funding from the MIT Libraries.
	Today, data science is a form of power. It has been used to expose injustice, improve health outcomes, and topple governments. But it has also been used to discriminate, police, and surveil. This potential for good, on the one hand, and harm, on the other, makes it essential to ask: Data science by whom? Data science for whom? Data science with whose interests in mind? The narratives around big data and data science are overwhelmingly white, male, and techno-heroic. In Data Feminism, Catherine D'Ignazio and Lauren Klein present a new way of thinking about data science and data ethics‚Äîone that is informed by intersectional feminist thought.
	Illustrating data feminism in action, D'Ignazio and Klein show how challenges to the male/female binary can help challenge other hierarchical (and empirically wrong) classification systems. They explain how, for example, an understanding of emotion can expand our ideas about effective data visualization, and how the concept of invisible labor can expose the significant human efforts required by our automated systems. And they show why the data never, ever ‚Äúspeak for themselves.‚Äù
	Data Feminism offers strategies for data scientists seeking to learn how feminism can help them work toward justice, and for feminists who want to focus their efforts on the growing field of data science. But Data Feminism is about much more than gender. It is about power, about who has it and who doesn't, and about how those differentials of power can be challenged and changed.},
	language = {eng},
	publisher = {MIT Libraries Experimental Collections Fund},
	author = {D'Ignazio, Catherine and Klein, Lauren F.},
	year = {2020},
	doi = {10.7551/mitpress/11805.001.0001},
	keywords = {artificial intelligence, Big data, Book Industry Communication, class, Data Science, emancipation, Feminism, Feminism \& feminist theory, Feminism and science, Gender studies, gender groups, genderqueer, Impact of science \& technology on society, Information Science, intersectionality, JFSJ5 Gender studies: transsexuals \& hermaphroditism, justice, Mathematics \& science, MeToo, non-binary, power, Power (Social sciences), Quantitative research, race, Science: general issues, sexuality, Social groups, Social issues \& processes, Society \& culture: general, Society \& social sciences},
}

@book{abbateRecodingGenderWomen2012,
	address = {Cambridge, UNITED STATES},
	title = {Recoding {Gender}: {Women}'s {Changing} {Participation} in {Computing}},
	isbn = {978-0-262-30546-4},
	shorttitle = {Recoding {Gender}},
	url = {http://ebookcentral.proquest.com/lib/washington/detail.action?docID=3339524},
	abstract = {The untold history of women and computing: how pioneering women succeeded in a field shaped by gender biases. Today, women earn a relatively low percentage of computer science degrees and hold proportionately few technical computing jobs. Meanwhile, the stereotype of the male "computer geek" seems to be everywhere in popular culture. Few people know that women were a significant presence in the early decades of computing in both the United States and Britain. Indeed, programming in postwar years was considered woman's work (perhaps in contrast to the more manly task of building the computers themselves). In Recoding Gender, Janet Abbate explores the untold history of women in computer science and programming from the Second World War to the late twentieth century. Demonstrating how gender has shaped the culture of computing, she offers a valuable historical perspective on today's concerns over women's underrepresentation in the field. Abbate describes the experiences of women who worked with the earliest electronic digital computers: Colossus, the wartime codebreaking computer at Bletchley Park outside London, and the American ENIAC, developed to calculate ballistics. She examines postwar methods for recruiting programmers, and the 1960s redefinition of programming as the more masculine "software engineering." She describes the social and business innovations of two early software entrepreneurs, Elsie Shutt and Stephanie Shirley; and she examines the career paths of women in academic computer science. Abbate's account of the bold and creative strategies of women who loved computing work, excelled at it, and forged successful careers will provide inspiration for those working to change gendered computing culture.},
	urldate = {2023-12-10},
	publisher = {MIT Press},
	author = {Abbate, Janet},
	year = {2012},
	keywords = {Women in computer science},
}

@book{hicksProgrammedInequalityHow2017,
	address = {Cambridge, UNITED STATES},
	title = {Programmed {Inequality}: {How} {Britain} {Discarded} {Women} {Technologists} and {Lost} {Its} {Edge} in {Computing}},
	isbn = {978-0-262-34294-0},
	shorttitle = {Programmed {Inequality}},
	url = {http://ebookcentral.proquest.com/lib/washington/detail.action?docID=6246618},
	abstract = {This "sobering tale of the real consequences of gender bias" explores how Britain lost its early dominance in computing by systematically discriminating against its most qualified workers: women. (Harvard Magazine) In 1944, Britain led the world in electronic computing. By 1974, the British computer industry was all but extinct. What happened in the intervening thirty years holds lessons for all postindustrial superpowers. As Britain struggled to use technology to retain its global power, the nation's inability to manage its technical labor force hobbled its transition into the information age. In Programmed Inequality, Mar Hicks explores the story of labor feminization and gendered technocracy that undercut British efforts to computerize. That failure sprang from the government's systematic neglect of its largest trained technical workforce simply because they were women. Women were a hidden engine of growth in high technology from World War II to the 1960s. As computing experienced a gender flip, becoming male-identified in the 1960s and 1970s, labor problems grew into structural ones and gender discrimination caused the nation's largest computer user--the civil service and sprawling public sector--to make decisions that were disastrous for the British computer industry and the nation as a whole. Drawing on recently opened government files, personal interviews, and the archives of major British computer companies, Programmed Inequality takes aim at the fiction of technological meritocracy. Hicks explains why, even today, possessing technical skill is not enough to ensure that women will rise to the top in science and technology fields. Programmed Inequality shows how the disappearance of women from the field had grave macroeconomic consequences for Britain, and why the United States risks repeating those errors in the twenty-first century.},
	urldate = {2023-12-10},
	publisher = {MIT Press},
	author = {Hicks, Mar},
	year = {2017},
}

@misc{mcilwainBlackSoftwareInternet2020,
	title = {Black software: the internet and racial justice, from the {AfroNet} to {Black} {Lives} {Matter}},
	shorttitle = {Black software},
	url = {https://orbiscascade-washington.primo.exlibrisgroup.com/permalink/01ALLIANCE_UW/8iqusu/alma99162262159401452},
	abstract = {Black Software, for the first time, chronicles the long relationship between African Americans, computing technology, and the Internet. Through new archival sources and the voices of many of those who lived and made this history, this book centralizes African Americans' role in the Internet's creation and evolution, illuminating both the limits and possibilities for using digital technology to push for racial justice in the United States and across the globe.},
	language = {eng},
	publisher = {Oxford University Press},
	author = {McIlwain, Charlton D.},
	year = {2020},
	keywords = {21st century, African Americans, African Americans and mass media, Communication, Internet, LANGUAGE ARTS \& DISCIPLINES, Linguistics, Political aspects, Politics and government, Racism, Racism against Black people, Social justice, United States},
}

@book{browneDarkMattersSurveillance2015,
	title = {Dark {Matters}: {On} the {Surveillance} of {Blackness}},
	isbn = {978-0-8223-7530-2},
	shorttitle = {Dark {Matters}},
	url = {https://orbiscascade-washington.primo.exlibrisgroup.com/permalink/01ALLIANCE_UW/8iqusu/alma99161921055701452},
	abstract = {In Dark Matters Simone Browne locates the conditions of blackness as a key site through which surveillance is practiced, narrated, and resisted. She shows how contemporary surveillance technologies and practices are informed by the long history of racial formation and by the methods of policing black life under slavery, such as branding, runaway slave notices, and lantern laws. Placing surveillance studies into conversation with the archive of transatlantic slavery and its afterlife, Browne draws from black feminist theory, sociology, and cultural studies to analyze texts as diverse as the methods of surveilling blackness she discusses: from the design of the eighteenth-century slave ship Brooks, Jeremy Bentham's Panopticon, and The Book of Negroes, to contemporary art, literature, biometrics, and post-9/11 airport security practices. Surveillance, Browne asserts, is both a discursive and material practice that reifies boundaries, borders, and bodies around racial lines, so much so that the surveillance of blackness has long been, and continues to be, a social and political norm.},
	language = {en},
	urldate = {2023-12-10},
	publisher = {Duke University Press},
	author = {Browne, Simone},
	month = sep,
	year = {2015},
	doi = {10.1215/9780822375302},
}

@book{nobleAlgorithmsOppressionHow2018a,
	address = {New York, UNITED STATES},
	title = {Algorithms of {Oppression}: {How} {Search} {Engines} {Reinforce} {Racism}},
	isbn = {978-1-4798-3364-1},
	shorttitle = {Algorithms of {Oppression}},
	url = {https://orbiscascade-washington.primo.exlibrisgroup.com/permalink/01ALLIANCE_UW/8iqusu/alma99162068349301452},
	abstract = {A revealing look at how negative biases against women of color are embedded in search engine results and algorithms Run a Google search for "black girls"--what will you find? "Big Booty" and other sexually explicit terms are likely to come up as top search terms. But, if you type in "white girls," the results are radically different. The suggested porn sites and un-moderated discussions about "why black women are so sassy" or "why black women are so angry" presents a disturbing portrait of black womanhood in modern society. In Algorithms of Oppression, Safiya Umoja Noble challenges the idea that search engines like Google offer an equal playing field for all forms of ideas, identities, and activities. Data discrimination is a real social problem; Noble argues that the combination of private interests in promoting certain sites, along with the monopoly status of a relatively small number of Internet search engines, leads to a biased set of search algorithms that privilege whiteness and discriminate against people of color, specifically women of color. Through an analysis of textual and media searches as well as extensive research on paid online advertising, Noble exposes a culture of racism and sexism in the way discoverability is created online. As search engines and their related companies grow in importance--operating as a source for email, a major vehicle for primary and secondary school learning, and beyond--understanding and reversing these disquieting trends and discriminatory practices is of utmost importance. An original, surprising and, at times, disturbing account of bias on the internet, Algorithms of Oppression contributes to our understanding of how racism is created, maintained, and disseminated in the 21st century.},
	urldate = {2023-12-10},
	publisher = {New York University Press},
	author = {Noble, Safiya Umoja},
	year = {2018},
	keywords = {Discrimination, Google, Search engines-Sociological aspects},
}

@misc{WatchCodedBias,
	title = {{Coded} {Bias}},
	url = {https://www.netflix.com/title/81328723},
	abstract = {This documentary investigates the bias in algorithms after M.I.T. Media Lab researcher Joy Buolamwini uncovered flaws in facial recognition technology.},
	language = {en},
	urldate = {2023-12-10},
	publisher = {7th Empire Media, Chicken And Egg Pictures, Ford Foundation - Just Films},
	author = {Kantayya, Shalini},
	collaborator = {Seward, Christopher and Rachman, Paul and Engfehr, Kurt and Buolamwini, Joy and Broussard, Meredith and O\&apos;Neil, Cathy},
	month = nov,
	year = {2020},
}

@book{gillespieCustodiansInternetPlatforms2018,
	address = {New Haven, UNITED STATES},
	title = {Custodians of the {Internet}: {Platforms}, {Content} {Moderation}, and the {Hidden} {Decisions} {That} {Shape} {Social} {Media}},
	isbn = {978-0-300-23502-9},
	shorttitle = {Custodians of the {Internet}},
	url = {https://orbiscascade-washington.primo.exlibrisgroup.com/permalink/01ALLIANCE_UW/8iqusu/alma99162362661601452},
	abstract = {A revealing and gripping investigation into how social media platforms police what we post online--and the large societal impact of these decisions Most users want their Twitter feed, Facebook page, and YouTube comments to be free of harassment and porn. Whether faced with "fake news" or livestreamed violence, "content moderators"--who censor or promote user-posted content--have never been more important. This is especially true when the tools that social media platforms use to curb trolling, ban hate speech, and censor pornography can also silence the speech you need to hear. In this revealing and nuanced exploration, award-winning sociologist and cultural observer Tarleton Gillespie provides an overview of current social media practices and explains the underlying rationales for how, when, and why these policies are enforced. In doing so, Gillespie highlights that content moderation receives too little public scrutiny even as it is shapes social norms and creates consequences for public discourse, cultural production, and the fabric of society. Based on interviews with content moderators, creators, and consumers, this accessible, timely book is a must-read for anyone who's ever clicked "like" or "retweet."},
	urldate = {2023-12-10},
	publisher = {Yale University Press},
	author = {Gillespie, Tarleton},
	year = {2018},
	keywords = {Social media-Censorship},
}

@misc{robertsScreenContentModeration2019,
	title = {Behind the screen: content moderation in the shadows of social media},
	shorttitle = {Behind the screen},
	url = {https://orbiscascade-washington.primo.exlibrisgroup.com/permalink/01ALLIANCE_UW/8iqusu/alma99162217744201452},
	abstract = {An eye-opening look at the invisible workers who protect us from seeing humanity's worst on today's commercial internet. Social media on the internet can be a nightmarish place. A primary shield against hateful language, violent videos, and online cruelty uploaded by users is not an algorithm. It is people. Mostly invisible by design, more than 100,000 commercial content moderators evaluate posts on mainstream social media platforms: enforcing internal policies, training artificial intelligence systems, and actively screening and removing offensive material--sometimes thousands of items per day. Sarah T. Roberts, an award-winning social media scholar, offers the first extensive ethnographic study of the commercial content moderation industry. Based on interviews with workers from Silicon Valley to the Philippines, at boutique firms and at major social media companies, she contextualizes this hidden industry and examines the emotional toll it takes on its workers. This revealing investigation of the people "behind the screen" offers insights into not only the reality of our commercial internet but the future of globalized labor in the digital age.},
	language = {eng},
	publisher = {Yale University Press},
	author = {Roberts, Sarah T.},
	year = {2019},
	keywords = {Censorship, Internet governance, Management, Media Studies, PSYCHOLOGY, Social media, Social Psychology, SOCIAL SCIENCE, User-generated content},
}

@book{burgessSAGEHandbookSocial2018,
	address = {55 City Road, London},
	title = {The {SAGE} {Handbook} of {Social} {Media}},
	url = {https://orbiscascade-washington.primo.exlibrisgroup.com/permalink/01ALLIANCE_UW/8iqusu/alma99162105658401452},
	abstract = {In terms of media and communication history, we are arguably in the midst of a social media paradigm. Well-known platforms like Twitter and Facebook have gone from being viewed as mere sites of teenage distraction to becoming embedded ICT infrastructure in mainstream organisations across the society, culture, and economy; such platforms, their uses, and their politics are increasingly entangled with everyday life, work, and relationships. For the past decade there has been a burgeoning interest in social media. This highly international Handbook addresses the most significant research themes, methodological approaches and debates in this field via substantial chapters specially commissioned from leading scholars coming from a range of disciplinary perspectives centered on but extending beyond the social sciences and humanities.},
	urldate = {2023-12-10},
	publisher = {SAGE Publications},
	author = {Burgess, Jean and Marwick, Alice and Poell, Thomas},
	year = {2018},
	doi = {10.4135/9781473984066},
	keywords = {Facebook, internet, new media, political economy, social interaction, social media, social networking, social networks, social research, Twitter},
}

@book{takhteyevCodingPlacesSoftware2012,
	title = {Coding {Places}: {Software} {Practice} in a {South} {American} {City}},
	isbn = {978-0-262-30559-4},
	shorttitle = {Coding {Places}},
	url = {https://orbiscascade-washington.primo.exlibrisgroup.com/permalink/01ALLIANCE_UW/8iqusu/alma99161981926801452},
	abstract = {An examination of software practice in Brazil that reveals both the globalization and the localization of software development. Software development would seem to be a quintessential example of today's Internet-enabled "knowledge work"--A global profession not bound by the constraints of geography. In Coding Places, Yuri Takhteyev looks at the work of software developers who inhabit two contexts: a geographical area--in this case, greater Rio de Janeiro--and a "world of practice," a global system of activities linked by shared meanings and joint practice. The work of the Brazilian developers, Takhteyev discovers, reveals a paradox of the world of software: it is both diffuse and sharply centralized. The world of software revolves around a handful of places--in particular, the San Francisco Bay area--that exercise substantial control over both the material and cultural elements of software production. Takhteyev shows how in this context Brazilian software developers work to find their place in the world of software and to bring its benefits to their city. Takhteyev's study closely examines Lua, an open source programming language developed in Rio but used in such internationally popular products as World of Warcraft and Angry Birds. He shows that Lua had to be separated from its local origins on the periphery in order to achieve success abroad. The developers, Portuguese speakers, used English in much of their work on Lua. By bringing to light the work that peripheral practitioners must do to give software its seeming universality, Takhteyev offers a revealing perspective on the not-so-flat world of globalization.},
	language = {en},
	urldate = {2023-12-10},
	publisher = {The MIT Press},
	author = {Takhteyev, Yuri},
	month = sep,
	year = {2012},
	doi = {10.7551/mitpress/9109.001.0001},
}

@misc{eubanksAutomatingInequalityHow2018,
	address = {New York, NY},
	edition = {First edition},
	title = {Automating inequality: how high-tech tools profile, police, and punish the poor},
	isbn = {978-1-250-07431-7},
	shorttitle = {Automating inequality},
	url = {https://orbiscascade-washington.primo.exlibrisgroup.com/permalink/01ALLIANCE_UW/8iqusu/alma99162064355601452},
	abstract = {The state of Indiana denied one million applications for health care, food stamps, and cash benefits in three years - because a new computer system interpreted any application mistake as "failure to cooperate." In Los Angeles, an algorithm calculates the comparative vulnerability of tens of thousands of homeless people in order to prioritize them for an inadequate pool of housing resources. In Pittsburgh, a child welfare agency uses a statistical model to try to predict which children might be future victims of abuse or neglect. Since the dawn of the digital age, decision making in finance, employment, politics, health care, and human services has undergone revolutionary change. Today, automated systems control which neighborhoods get policed, which families attain resources, and who is investigated for fraud. While we all live under this new regime of data, the most invasive and punitive systems are aimed at the poor. Virginia Eubanks systematically investigates the impacts of data mining, policy algorithms, and predictive risk models on economic inequality and democracy in America. Full of heart-wrenching and eye-opening stories, this deeply researched and passionate book could not be timelier.},
	language = {eng},
	publisher = {St. Martin's Press},
	author = {Eubanks, Virginia},
	year = {2018},
	keywords = {Computers, COMPUTERS, Data processing, Internet, Law and legislation, POLITICAL SCIENCE, Poor, Poverty, Poverty \& Homelessness, Public Policy, Public welfare, Services for, Social aspects, Social Aspects, Social Classes \& Economic Disparity, SOCIAL SCIENCE, Social Services \& Welfare, United States},
}

@book{grayGhostWorkHow2019,
	address = {Boston, United States},
	title = {Ghost {Work}: {How} to {Stop} {Silicon} {Valley} from {Building} a {New} {Global} {Underclass}},
	isbn = {978-1-328-56628-7},
	shorttitle = {Ghost {Work}},
	url = {https://orbiscascade-washington.primo.exlibrisgroup.com/permalink/01ALLIANCE_UW/8iqusu/alma99162207131801452},
	abstract = {In the spirit of Nickel and Dimed, a necessary and revelatory expose of the invisible human workforce that powers the web--and that foreshadows the true future of work. Hidden beneath the surface of the web, lost in our wrong-headed debates about AI, a new menace is looming. Anthropologist Mary L. Gray and computer scientist Siddharth Suri team up to unveil how services delivered by companies like Amazon, Google, Microsoft, and Uber can only function smoothly thanks to the judgment and experience of a vast, invisible human labor force. These people doing "ghost work" make the internet seem smart. They perform high-tech piecework: flagging X-rated content, proofreading, designing engine parts, and much more. An estimated 8 percent of Americans have worked at least once in this "ghost economy," and that number is growing. They usually earn less than legal minimums for traditional work, they have no health benefits, and they can be fired at any time for any reason, or none. There are no labor laws to govern this kind of work, and these latter-day assembly lines draw in--and all too often overwork and underpay--a surprisingly diverse range of workers: harried young mothers, professionals forced into early retirement, recent grads who can't get a toehold on the traditional employment ladder, and minorities shut out of the jobs they want. Gray and Suri also show how ghost workers, employers, and society at large can ensure that this new kind of work creates opportunity--rather than misery--for those who do it.},
	urldate = {2023-12-10},
	publisher = {Houghton Mifflin Harcourt Publishing Company},
	author = {Gray, Mary L. and Suri, Siddharth},
	year = {2019},
	keywords = {Artificial intelligence-Economic aspects., Automation-Economic aspects., Labor supply-Effect of automation on., Technological unemployment.},
}

@misc{zuboffAgeSurveillanceCapitalism2019,
	address = {New York, NY},
	edition = {First edition},
	title = {The age of surveillance capitalism: the fight for a human future at the new frontier of power},
	isbn = {978-1-610-39569-4},
	shorttitle = {The age of surveillance capitalism},
	url = {https://orbiscascade-washington.primo.exlibrisgroup.com/permalink/01ALLIANCE_UW/8iqusu/alma99162177355601452},
	abstract = {Zuboff tackles the social, political, business, personal, and technological meaning of "surveillance capitalism" as an unprecedented new market form. It is not simply about tracking us and selling ads, it is the business model for an ominous new marketplace that aims at nothing less than predicting and modifying our everyday behavior-- where we go, what we do, what we say, how we feel, who we're with. She shows that the threat has shifted from a totalitarian "big brother" state to a universal global architecture of automatic sensors and smart capabilities, free from democratic oversight and control.},
	language = {eng},
	publisher = {PublicAffairs},
	author = {Zuboff, Shoshana},
	year = {2019},
	keywords = {Anthropology, Behavior modification, Big data, Consumer behavior, Consumer profiling, Cultural, Cultural Policy, Data processing, Economic aspects, Forecasting, Information technology, POLITICAL SCIENCE, Popular Culture, Public Policy, Social aspects, SOCIAL SCIENCE},
}

@misc{oneilWeaponsMathDestruction2016,
	address = {New York, NY},
	edition = {First edition},
	title = {Weapons of math destruction: how big data increases inequality and threatens democracy},
	isbn = {978-0-553-41881-1},
	shorttitle = {Weapons of math destruction},
	url = {https://orbiscascade-washington.primo.exlibrisgroup.com/permalink/01ALLIANCE_UW/8iqusu/alma99161951137601452},
	abstract = {We live in the age of the algorithm. Increasingly, the decisions that affect our lives (where we go to school, whether we get a car loan, how much we pay for health insurance) are being made not by humans, but by mathematical models. In theory, this should lead to greater fairness: everyone is judged according to the same rules, and bias is eliminated. But as Cathy O'Neil reveals in this book, the opposite is true. The models being used today are opaque, unregulated, and uncontestable, even when they are wrong. Most troubling, they reinforce discrimination: if a poor student can't get a loan because a lending model deems him too risky (by virtue of his zip code), he is then cut off from the kind of education that could pull him out of poverty, and a vicious spiral ensues. Models are propping up the lucky and punishing the downtrodden, creating a 'toxic cocktail for democracy.' Welcome to the dark side of big data. Tracing the arc of a person's life, O'Neil exposes the black box models that shape our future, both as individuals and as a society. These 'weapons of math destruction' score teachers and students, sort r√©sum√©s, grant (or deny) loans, evaluate workers, target voters, set parole, and monitor our health. O'Neil calls on modelers to take more responsibility for their algorithms and on policy makers to regulate their use. But in the end, it is up to us to become more savvy about the models that govern our lives.},
	language = {eng},
	publisher = {Crown},
	author = {O'Neil, Cathy},
	year = {2016},
	keywords = {21st century, Big data, BUSINESS \& ECONOMICS, Democracy, Mathematical models, Moral and ethical aspects, Political aspects, POLITICAL SCIENCE, politics, Politics, Practical, Privacy \& Surveillance, Public Policy, Social aspects, Social conditions, Social indicators, SOCIAL SCIENCE, Statistics, United States},
}

@book{costanza-chockDesignJusticeCommunityled2020,
	address = {Cambridge, Massachesetts},
	series = {Information policy series},
	title = {Design justice: community-led practices to build the worlds we need},
	isbn = {978-0-262-35686-2},
	shorttitle = {Design justice},
	url = {https://orbiscascade-washington.primo.exlibrisgroup.com/permalink/01ALLIANCE_UW/8iqusu/alma99162363060401452},
	abstract = {An exploration of how design might be led by marginalized communities, dismantle structural inequality, and advance collective liberation and ecological survival. What is the relationship between design, power, and social justice? "Design justice" is an approach to design that is led by marginalized communities and that aims explicitly to challenge, rather than reproduce, structural inequalities. It has emerged from a growing community of designers in various fields who work closely with social movements and community-based organizations around the world. This book explores the theory and practice of design justice, demonstrates how universalist design principles and practices erase certain groups of people--specifically, those who are intersectionally disadvantaged or multiply burdened under the matrix of domination (white supremacist heteropatriarchy, ableism, capitalism, and settler colonialism)--and invites readers to "build a better world, a world where many worlds fit; linked worlds of collective liberation and ecological sustainability." Along the way, the book documents a multitude of real-world community-led design practices, each grounded in a particular social movement. Design Justice goes beyond recent calls for design for good, user-centered design, and employment diversity in the technology and design professions; it connects design to larger struggles for collective liberation and ecological survival.},
	language = {eng},
	publisher = {The MIT Press},
	author = {Costanza-Chock, Sasha},
	year = {2020},
	keywords = {Design, DESIGN, General, Industrial design, Moral and ethical aspects, Political aspects, Power (Social sciences), Social aspects, Social justice, sustainable architecture, Sustainable design},
}

@book{mullaneyYourComputerFire2021,
	address = {Cambridge, Massachusetts},
	title = {Your computer is on fire},
	isbn = {978-0-262-36077-7},
	url = {https://orbiscascade-washington.primo.exlibrisgroup.com/permalink/01ALLIANCE_UW/8iqusu/alma99162423945901452},
	abstract = {Collection of arguments about STEM fields' blind spots in computing and a deliberately provocative underscoring of humanists' appeals for a "wake up call" in computing culture.},
	language = {eng},
	publisher = {The MIT Press},
	author = {Mullaney, Thomas S. and Peters, Benjamin and Hicks, Mar and Philip, Kavita},
	year = {2021},
	doi = {10.7551/mitpress/10993.001.0001},
	keywords = {Computers, Information technology, Social aspects},
}

@misc{wachter-boettcherTechnicallyWrongSexist2018,
	address = {New York, NY},
	edition = {Norton paperback edition},
	title = {Technically wrong: sexist apps, biased algorithms, and other threats of toxic tech},
	isbn = {978-0-393-35604-5},
	shorttitle = {Technically wrong},
	url = {https://orbiscascade-washington.primo.exlibrisgroup.com/permalink/01ALLIANCE_UW/8iqusu/alma99329653362401451},
	abstract = {A revealing look at how tech industry bias and blind spots get baked into digital products--and harm us all. Buying groceries, tracking our health, finding a date: whatever we want to do, odds are that we can now do it online. But few of us ask why all these digital products are designed the way they are. It's time we change that. Many of the services we rely on are full of oversights, biases, and downright ethical nightmares: Chatbots that harass women. Signup forms that fail anyone who's not straight. Social media sites that send peppy messages about dead relatives. Algorithms that put more black people behind bars. Sara Wachter-Boettcher takes an unflinching look at the values, processes, and assumptions that lead to these and other problems. Technically Wrong demystifies the tech industry, leaving those of us on the other side of the screen better prepared to make informed choices about the services we use--and demand more from the companies behind them.},
	language = {eng},
	publisher = {W.W. Norton \& Company, Inc.},
	author = {Wachter-Boettcher, Sara},
	month = oct,
	year = {2018},
	keywords = {Business failures, Moral and ethical aspects, New products, Social aspects, System failures (Engineering), Technology},
}

@book{saundersMediaEthicsFree2018,
	address = {New York},
	title = {Media {Ethics}, {Free} {Speech}, and the {Requirements} of {Democracy}},
	isbn = {978-0-203-70244-4},
	url = {https://www.taylorfrancis.com/books/edit/10.4324/9780203702444/media-ethics-free-speech-requirements-democracy-carl-fox-joe-saunders},
	abstract = {How we understand, protect, and discharge our rights and responsibilities as citizens in a democratic society committed to the principle of political equality},
	publisher = {Routledge},
	editor = {Saunders, Joe, and Fox, Carl},
	month = dec,
	year = {2018},
	doi = {10.4324/9780203702444},
}

@book{ViralJustice2022,
	title = {Viral {Justice:} {How We Grow the World We Want}},
	isbn = {978-0-691-22288-2},
	shorttitle = {Viral {Justice}},
	url = {https://press.princeton.edu/books/hardcover/9780691222882/viral-justice},
	abstract = {From the author of Race After Technology, an inspiring vision of how we can build a more just world‚Äîone small change at a time‚ÄúA true gift to our movements for justice.‚Äù‚ÄîMichelle Alexander, author of The New Jim Crow},
	language = {en},
	urldate = {2023-12-10},
	publisher = {Princeton University Press},
	author = {Benjamin, Ruha},
	month = oct,
	year = {2022},
}

@misc{MetaDevelopers,
	title = {Meta for {Developers}},
	copyright = {Meta Platforms, Inc.},
	url = {https://developers.facebook.com/},
	abstract = {Code to connect people with Facebook for Developers. Explore AI, business tools, gaming, open source, publishing, social hardware, social integration, and virtual reality. Learn about Facebook‚Äôs global programs to educate and connect developers.},
	language = {en},
	urldate = {2023-12-10},
	publisher = {Meta for Developers},
	year = {2023},
}

@misc{APIReferenceFacebook,
	title = {{API} {Reference} ‚Äî {Facebook} {SDK} for {Python} 4.0.0-pre documentation},
	copyright = {Meta Platforms, Inc.},
	url = {https://facebook-sdk.readthedocs.io/en/latest/api.html},
	urldate = {2023-12-10},
	abstract = {This client library is designed to support the Facebook Graph API and the official Facebook JavaScript SDK, which is the canonical way to implement Facebook authentication. You can read more about the Graph API by accessing its official documentation.},
	publisher = {Read the Docs},
	organization = {Mobolic},
	year = {2015},
}

@misc{TikTokDevelopers,
	title = {{TikTok} for {Developers}},
	copyright = {TikTok},
	url = {https://developers.tiktok.com/},
	abstract = {Build awesome experiences and powerful tools that inspire creativity and allow users to create, connect, and share the world},
	language = {en},
	urldate = {2023-12-10},
	organization = {TikTok},
	year = {2023},
}

@misc{GettingStartedGetting,
	title = {Getting Started with {Official Account Developer Mode}},
	copyright = {Tencent},
	url = {https://developers.weixin.qq.com/doc/offiaccount/en/Getting_Started/Getting_Started_Guide.html},
	language = {en},
	urldate = {2023-12-10},
	publisher = {Weixin Docs},
	month = jan,
	year = {2013},
}

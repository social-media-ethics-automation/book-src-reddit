# Ethical Analysis of Recommendation Algorithms

When we look at ethics and responsibility in regards to recommendation algorithms, it can be helpful to consider the difference between individual analysis and systemic analysis.

## [Individual vs. Systemic Analysis](https://en.wikipedia.org/wiki/Systemic_bias) {cite:p}`SystemicBias2023`
__Individual analysis__ focuses on the behavior, bias, and responsibility an individual has, while __systemic analysis__ focuses on the how organizations and rules may have their own behaviors, biases, and responsibility that arenâ€™t necessarily connected to what any individual inside intends.

For example, there were differences in US criminal sentencing guidelines between crack cocaine vs. powder cocaine in the 90s. The guidelines suggested harsher sentences on the version of cocaine more commonly used by Black people, and lighter sentences on the version of cocaine more commonly used by white people. Therefore, when these guidelines were followed, they had have racially biased (that is, racist) outcomes regardless of intent or bias of the individual judges. (See: https://en.wikipedia.org/wiki/Fair_Sentencing_Act) {cite:p}`FairSentencingAct2023`.

## Recommendation Algorithms as Systems
Similarly, recommendation algorithms are rules set in place that might produce biased, unfair, or unethical outcomes. This can happen whether or not the creators of the algorithm intended these outcomes. Once these algorithms are in place though, the have an influence on what happens on a social media site. Individuals still have responsibility with how they behave, but the system itself may be set up so that individual efforts cannot not be overcome the problems in the system.

```{figure} structural_problem_personal_choices.png
---
width: 500px
name: structural_problem_personal_choices_fig
alt: "Tweet from Kelsey D. Atherton (@AthertonKD): Oh, you're experiencing a structural problem? Have you ever considered trying different personal choices instead?"
---
[A tweet](https://twitter.com/AthertonKD/status/1120376944061583360) {cite:p}`kelseyd.atherton[@athertonkd]OhYouRe2019a` highlighting the difference between structural problems (systemic analysis) and personal choices (individual analysis).
```

Sometimes though, individuals are still blamed for systemic problems. For example, Elon Musk, who has the power to change Twitters recommendation algorithm, blames the users for the results:

```{figure} musk_algorithm.png
---
width: 500px
name: musk_algorithm_fig
alt: "Tweet from Elon Musk (@elonmusk): Trashing accounts that you hate will cause our algorithm to show you more of those accounts, as it is keying off of your interactions. Basically saying if you love trashing *that* account, then you will probably also love trashing *this* account. Not actually wrong lol."
---
[A tweet](https://twitter.com/elonmusk/status/1615194151737520128) {cite:p}`elonmusk[@elonmusk]TrashingAccountsThat2023` from current Twitter owner Elon Musk blaming users for how the recommendation algorithm interprets their behavior.
```

Elon Musk's view expressed in that tweet is different than some of the ideas of the previous owners, who at least [tried to figure out how to make Twitter's algorithm support healthier conversation](https://www.vox.com/2019/3/8/18245536/exclusive-twitter-healthy-conversations-dunking-research-product-incentives) {cite:p}`wagnerTwitterAmbitiousPlan2019a`. 

Though even modifying a recommendation algorithm has limits in what it can do, as social groups and human behavior may be able to overcome the recommendation algorithms influence.